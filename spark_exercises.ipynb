{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75543be5-0536-409f-a79d-baffa5c84f37",
   "metadata": {},
   "source": [
    "### Using Spark to Query The Flight Delay Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35aead-a381-403a-8b81-a24e3cc4f817",
   "metadata": {},
   "source": [
    "Practice Spark with a dataset of flight arrival and departure details for all commercial flights in the USA for a month. Ensure you use Spark `DataFrames` and run on your Databricks account. Our aim is to \n",
    "The dataset can be downloaded [here](https://www.dropbox.com/s/egrza8zt8r0zyty/flight_info.csv?dl=1).\n",
    "Field details can be found [here](https://www.dropbox.com/scl/fi/dtab1jaa8amv2rz4zthsm/flight_info.info?rlkey=qojb5t58i71gtqkilxvl60rns&dl=0). Note the info file contains columns that were removed from the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1244ef29-2b72-42d4-8b26-731db6edf10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/05 09:42:46 WARN Utils: Your hostname, Ts-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 168.105.95.215 instead (on interface en0)\n",
      "23/10/05 09:42:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/05 09:42:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Ini from cheatsheet & Spark intro_1\n",
    "\n",
    "from pyspark import SparkContext # Spark intro_1.  Cheatsheet adds \"SparkConf\"\n",
    "# conf = (SparkConf().setMaster(\"local\").setAppName(\"My app\" ).set(\"spark.executor.memory\",\"1g\" )) - from cheatsheet\n",
    "# sc = SparkContext(conf = conf) - from cheatsheet\n",
    "sc = SparkContext() # Spark intro_1\n",
    "# sc.setLogLevel(\"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f6d1db-fbec-4a10-9081-140e612187c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdcad71-2421-45a8-8735-288bc036ce25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://168.105.95.215:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Spark intro_1\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a53029-88c9-4ccb-952f-4a3ea388eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version is 3.4.1\n",
      "Python version is 3.10\n",
      "The name of the master is local[*]\n"
     ]
    }
   ],
   "source": [
    "# From Spark intro_1\n",
    "\n",
    "print(f\"Spark version is {sc.version}\")\n",
    "\n",
    "print(f\"Python version is {sc.pythonVer}\")\n",
    "\n",
    "print(f\"The name of the master is {sc.master}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b649bb-8e3a-43ab-b8f6-b5cce3d6eb38",
   "metadata": {},
   "source": [
    "\n",
    "**Q1.** Load `flight_info.csv` into a Spark DataFrame `flight_info`. Also, determine the total number of entries in the file. \n",
    "*Note: Initialize a `sparkSession` before loading the data.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d699ca-cfb6-4989-9d0f-16c4ce1f0470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "session = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7661c9b1-3213-4d03-83b3-7ce08f6f1f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0='0', DayOfWeek='2', UniqueCarrier='AA', FlightNum='494', Origin='CLT', Dest='PHX', CRSDepTime='1619', DepTime='1616.0', TaxiOut='17.0', WheelsOff='1633.0', WheelsOn='1837.0', TaxiIn='5.0', CRSArrTime='1856', ArrTime='1842.0', Cancelled='0.0', CancellationCode=None, Distance='1773.0', CarrierDelay=None, WeatherDelay=None, NASDelay=None, SecurityDelay=None, LateAircraftDelay=None),\n",
       " Row(_c0='1', DayOfWeek='3', UniqueCarrier='AA', FlightNum='494', Origin='CLT', Dest='PHX', CRSDepTime='1619', DepTime='1614.0', TaxiOut='13.0', WheelsOff='1627.0', WheelsOn='1815.0', TaxiIn='6.0', CRSArrTime='1856', ArrTime='1821.0', Cancelled='0.0', CancellationCode=None, Distance='1773.0', CarrierDelay=None, WeatherDelay=None, NASDelay=None, SecurityDelay=None, LateAircraftDelay=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Write your code here\n",
    "\n",
    "flight_info_df = session.read.csv(\"data/flight_info.csv\", header=True)\n",
    "print(flight_info_df.count())\n",
    "flight_info_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58c68c9-d3db-48f3-9011-184f2ce4d014",
   "metadata": {},
   "source": [
    "Q2. Identify the airlines present in this dataset using the `UniqueCarrier` field. The field `UniqueCarrier` denotes the unique carrier code, e.g., `AA = American Airlines`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b84b9a1-77d4-43d4-8572-905e3159eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- DayOfWeek: string (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- CRSDepTime: string (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- TaxiOut: string (nullable = true)\n",
      " |-- WheelsOff: string (nullable = true)\n",
      " |-- WheelsOn: string (nullable = true)\n",
      " |-- TaxiIn: string (nullable = true)\n",
      " |-- CRSArrTime: string (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- Cancelled: string (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Distance: string (nullable = true)\n",
      " |-- CarrierDelay: string (nullable = true)\n",
      " |-- WeatherDelay: string (nullable = true)\n",
      " |-- NASDelay: string (nullable = true)\n",
      " |-- SecurityDelay: string (nullable = true)\n",
      " |-- LateAircraftDelay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_info_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414926ad-8b95-4e3f-94c6-885e83c99a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=====>                                                    (1 + 9) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|UniqueCarrier|\n",
      "+-------------+\n",
      "|           AA|\n",
      "|           EV|\n",
      "|           B6|\n",
      "|           DL|\n",
      "|           UA|\n",
      "|           NK|\n",
      "|           OO|\n",
      "|           F9|\n",
      "|           HA|\n",
      "|           WN|\n",
      "|           AS|\n",
      "|           VX|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Write your code here\n",
    "\n",
    "flight_info_df.select('UniqueCarrier').distinct().show()\n",
    "\n",
    "# sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40946970-693c-4d5a-a2cc-874132076d64",
   "metadata": {},
   "source": [
    "Q3. Calculate the number of flight delays for each carrier. Use `CRSDepTime` for scheduled departure and `DepTime` for actual departure. A flight is considered delayed if `DepTime > CRSDepTime`. List results in descending order of delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591c993-b670-4a5f-be33-0ad00d919717",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714cfda4-13d6-48fe-8859-8fe571abdb07",
   "metadata": {},
   "source": [
    "Q4. Load `airlines.csv` into a DataFrame airlines_info. Then, match it with flight_info to display the full name of each airline along with delay counts. The carrier code is in the 4th column of airlines.csv. Since this file lacks a header, inspect the column names assigned by Spark for your query.\n",
    "Expected Output: Rows containing UniqueCarrier, airline name, and delay count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412f53f-59af-4768-98ac-4bdcfc5f4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126d6b6-3660-4d91-ad79-08f2c8f0718f",
   "metadata": {},
   "source": [
    "Q5. Calculate the number of delays per airline per day, using `DayOfWeek` column in `flight_info`. Sort the data by `UniqueCarrier` and `DayOfWeek` (ascending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5731ef72-d741-406e-b4f2-a212c0c42819",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5ec4a-cb95-453c-b293-81b3582282ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalize delay counts per airline by the total number of flights for that carrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d0a2c-b695-480a-b493-a6dd1923f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
